import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# =========================
# è¨­å®š
# =========================
st.set_page_config(page_title="LLM Expert Web App", page_icon="ğŸ¤–", layout="centered")

# OpenAI APIã‚­ãƒ¼ã®å–å¾—ï¼ˆStreamlit Cloud ã§ã¯ã€[Settings] â†’ [Secrets] ã« OPENAI_API_KEY ã‚’å…¥ã‚Œã¦ãŠãï¼‰
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ Streamlit Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# =========================
# å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ï¼ˆA / Bï¼‰
# =========================
EXPERTS = {
    "A": {
        "label": "A: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ",
        "system": (
            "ã‚ãªãŸã¯ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚"
            "çµ±è¨ˆãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»å®Ÿé¨“è¨­è¨ˆãƒ»å¯è¦–åŒ–ã«ç²¾é€šã—ã€æ•°å¼ã‚„å…·ä½“ä¾‹ã‚’ç”¨ã„ã¦ã€"
            "å†ç¾å¯èƒ½ã§å®Ÿå‹™ã«æ´»ã‹ã›ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç°¡æ½”ã«æç¤ºã—ã¦ãã ã•ã„ã€‚"
        ),
    },
    "B": {
        "label": "B: UXãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼",
        "system": (
            "ã‚ãªãŸã¯ç†Ÿç·´ã®UXãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼èª²é¡Œã®æ´å¯Ÿã€æƒ…å ±è¨­è¨ˆã€ãƒšãƒ«ã‚½ãƒŠ/ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ­ãƒ¼ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã€"
            "å¯ç”¨æ€§ãƒ†ã‚¹ãƒˆã«åŸºã¥ãæ”¹å–„ææ¡ˆã‚’ã€å®Ÿè£…å¯èƒ½ãªç²’åº¦ã§åˆ†ã‹ã‚Šã‚„ã™ãæç¤ºã—ã¦ãã ã•ã„ã€‚"
        ),
    },
}

# =========================
# LLM å‘¼ã³å‡ºã—é–¢æ•°ï¼ˆè¦ä»¶ã®é–¢æ•°ï¼‰
#  - å…¥åŠ›: input_textï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼‰, expert_keyï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³é¸æŠå€¤ 'A' or 'B'ï¼‰
#  - å‡ºåŠ›: æ–‡å­—åˆ—ï¼ˆLLMã‹ã‚‰ã®å›ç­”ï¼‰
# =========================
def ask_llm(input_text: str, expert_key: str) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰(A/B)ã‚’å—ã‘ã€LLMã®å›ç­”ã‚’è¿”ã™ã€‚"""
    if expert_key not in EXPERTS:
        raise ValueError("Unknown expert key")

    system_prompt = EXPERTS[expert_key]["system"]

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("human", "{user_input}"),
        ]
    )

    llm = ChatOpenAI(
        api_key=OPENAI_API_KEY,
        model="gpt-4o-mini",   # å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´å¯ï¼ˆä¾‹: "gpt-4o"ï¼‰
        temperature=0.2,
    )
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"user_input": input_text})

# =========================
# UI
# =========================
st.title("ğŸ¤– LLM Expert Web App")
st.caption("LangChain + Streamlit ã§ä½œã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãª LLM ã‚¢ãƒ—ãƒª")

with st.expander("ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦ / ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
**æ¦‚è¦**  
- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’è¨˜å…¥ã—ã€**å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ï¼ˆA/Bï¼‰**ã‚’é¸æŠã—ã¦é€ä¿¡ã™ã‚‹ã¨ã€  
  é¸ã‚“ã å°‚é–€å®¶ã¨ã—ã¦ã®è¦–ç‚¹ãƒ»è¨€è‘‰é£ã„ã§ LLM ãŒå›ç­”ã—ã¾ã™ã€‚  
- ä»•çµ„ã¿ï¼šLangChain ã‚’ç”¨ã„ã€**é¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸ system ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**ã‚’çµ„ã¿ç«‹ã¦ã¦ LLM ã«æ¸¡ã—ã¦ã„ã¾ã™ã€‚

**ä½¿ã„æ–¹**  
1. **å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰**ã‚’é¸ã³ã¾ã™ï¼ˆA=ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ / B=UXãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ï¼‰ã€‚  
2. å…¥åŠ›æ¬„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜å…¥ã—ã¾ã™ï¼ˆä¾‹ï¼šèª²é¡Œã‚„è¦ä»¶ã€åˆ¶ç´„ã€ç¾çŠ¶ãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰ã€‚  
3. **é€ä¿¡**ã‚’æŠ¼ã™ã¨ã€ç”»é¢ä¸‹éƒ¨ã«å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
        """
    )

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆè¡¨ç¤ºã¯ãƒ©ãƒ™ãƒ«ã€å€¤ã¯ 'A' / 'B'ï¼‰
expert_choice = st.radio(
    "å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    options=list(EXPERTS.keys()),
    format_func=lambda k: EXPERTS[k]["label"],
    horizontal=True,
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("qa_form", clear_on_submit=False):
    user_text = st.text_area(
        "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè³ªå•ãƒ»ç›¸è«‡å†…å®¹ï¼‰",
        placeholder="ä¾‹ï¼šA/Bãƒ†ã‚¹ãƒˆã®è¨­è¨ˆã§æ‚©ã‚“ã§ã„ã¾ã™ã€‚åˆ†å‰²ã‚„å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã€æŒ‡æ¨™ã¯ã©ã†æ±ºã‚ã‚‹ã¹ãï¼Ÿ",
        height=150,
    )
    submitted = st.form_submit_button("é€ä¿¡ã™ã‚‹")

if submitted:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLM ã‹ã‚‰ã®å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
            try:
                answer = ask_llm(user_text, expert_choice)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.subheader("ğŸ§  å›ç­”")
                st.write(answer)